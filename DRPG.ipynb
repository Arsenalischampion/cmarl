{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate, GRU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    " \n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import os\n",
    "from tempfile import mkdtemp\n",
    "from werkzeug import secure_filename\n",
    "import requests\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from gym import spaces, logger\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np \n",
    "import time \n",
    "import csv\n",
    "import pandas as pd \n",
    "\n",
    "class MicroEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        print('__init__')\n",
    "        tstart = time.time()\n",
    "        #filename1=\"dqn_logsv4.csv\"\n",
    "        #self.fileHandle = open(filename1,\"w\")\n",
    "        #self.writer = csv.writer(self.fileHandle)\n",
    "        self.maxNode = 2 \n",
    "        self.minNode = 1 \n",
    "        self.node = 1\n",
    "        self.ip = '192.168.99.100'\n",
    "        self.cluster= False\n",
    "        #self.ip = subprocess.check_output([\"docker-machine\", \"ip\", \"new-mgr\"])\n",
    "        self.cpu_axis  = self.get_cpu_observation()\n",
    "        self.mem_axis = self.get_mem_observation()\n",
    "        self.disk_axis = self.get_disk_observation()\n",
    "        self.net_axis  = self.get_net_observation()\n",
    "        self.action_space = spaces.Discrete(10)\n",
    "        self.action_space = spaces.Box(0, 9, shape=(1, 1), dtype=np.int16)\n",
    "        high = np.array([\n",
    "            self.get_cpu_observation(),\n",
    "            self.get_mem_observation(),\n",
    "            self.get_disk_observation(),\n",
    "            self.get_net_observation()])\n",
    "        low = np.array([\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5)])\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "        self.seed()\n",
    "        self.obs= 0\n",
    "        self.obs = self.get_observation()\n",
    "        self.viewer = None\n",
    "        self.state = self.get_observation()\n",
    "        self.state_name = 's0'\n",
    "        self.attempt = 0 \n",
    "        self.steps_beyond_done = None\n",
    "        self.done = False\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False \n",
    "        #self.writer.writerow([\"timestamp\",\"state\", \"action\", \"reward\", \"maxUtility\", \"duration\", \"info\", \"# node\"])\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    def step(self, action):\n",
    "        #assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        action = np.floor(action)\n",
    "        state = self.get_observation()\n",
    "        #past_stat = self.state\n",
    "        #print(state)\n",
    "        #Find the Utility Prefernces \n",
    "        # Select action \n",
    "        # get the reward value\n",
    "        tstart = time.time()\n",
    "        maxUtility = np.amax(self.obs[:,4])\n",
    "        utilityType = np.argmax(self.obs[:,4])\n",
    "        if utilityType== 0:\n",
    "            self.adapte_cpu=True \n",
    "        elif utilityType== 1:\n",
    "            self.adapte_mem = True\n",
    "        elif utilityType== 2:\n",
    "            self.adapte_disk = True\n",
    "        elif utilityType== 3:\n",
    "            self.adapte_net = True\n",
    "        self.attempt += 1\n",
    "        #print('self.adapte_cpu: ', self.adapte_cpu, 'self.adapte_mem:', self.adapte_mem, 'self.adapte_disk:',self.adapte_disk,'self.adapte_net:', self.adapte_net )\n",
    "        done=False\n",
    "        reward=0\n",
    "        info=''\n",
    "        print (\"Starting Action: \", action)\n",
    "        if action==0:\n",
    "            #print(\"Stay in State S0\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward=  np.amax(self.obs[:,3])\n",
    "            self.state_name='s0'\n",
    "        elif action == 1:\n",
    "            #print(\"Stay in State S1\")\n",
    "            self.obs = self.get_observation()\n",
    "            done = True\n",
    "            self.state_name='s1'\n",
    "            reward=  1\n",
    "        elif action == 2:\n",
    "            self.obs = self.get_observation()\n",
    "            try:\n",
    "                response = requests.get('http://'+self.ip+':8888/services/vscale/web/'+ str(self.attempt) + '/' + str(self.cpu_axis[0])+'/'+str(self.cpu_axis[3]))\n",
    "                results = response.json()\n",
    "                if results['result']=='Service converged':\n",
    "                    done=True \n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1 - np.amax(self.obs[:,3]) \n",
    "                    self.state_name='s2'\n",
    "                    info = \"Scale Up Move to State S2\"\n",
    "                else:\n",
    "                    done= False\n",
    "                    print(results)\n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1- np.amax(self.obs[:,3])  \n",
    "                    print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                    self.state_name='s0'\n",
    "                    info = \"S2 => No Scale Move back to State S0\"\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                \n",
    "                pass\n",
    "\n",
    "        elif action == 3: \n",
    "            #print(\"Maintain Cluster State S4 and delete dangling docker containers\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward= 1 - np.amax(self.obs[:,3])\n",
    "            #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= False\n",
    "            self.state_name='s0'\n",
    "            info = \"delete dangling docker containers S3\"\n",
    "            cur_dir = os.getcwd()\n",
    "            filepath = os.path.join(cur_dir, 'cleancontainers.sh')\n",
    "            print (filepath)\n",
    "            res= subprocess.call(filepath, shell=True)\n",
    "            #print (res)\n",
    "            reward = 1\n",
    "            self.state_name='s3'\n",
    "            done = True\n",
    "        elif action == 4:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode):\n",
    "                #print(\"Add Node s4\")\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'addNode.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Add Node S4\"\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                self.state_name='s4'\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                self.node +=1\n",
    "            elif self.node==5:\n",
    "                    done=True \n",
    "                    reward= 1 \n",
    "                    self.state_name='s4'\n",
    "            else:\n",
    "                #print(\"go back to Cluster State at S0: \", self.attempt)\n",
    "                done= False\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                self.state_name='s0'\n",
    "        elif action == 5:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode and self.node > self.minNode ):\n",
    "                #print(\"Delete Node S5\")\n",
    "                self.state_name='s5'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'deleteNode.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                \n",
    "                info = \"Delete Node S5\"\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                self.node -=1\n",
    "            else:\n",
    "                #print(\"Maintain Cluster State at S0: \", self.attempt, self.node, self.minNode, self.maxNode)\n",
    "                done= False\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward)\n",
    "                self.state_name='s0'\n",
    "                if self.node==1:\n",
    "                    done=True \n",
    "                    reward= 1\n",
    "                    self.state_name='s5'\n",
    "        elif action==6:\n",
    "            self.obs = self.get_observation()\n",
    "            #print(\"freedisk Space S6\")\n",
    "            cur_dir = os.getcwd()\n",
    "            filepath = os.path.join(cur_dir, 'freedisk.sh')\n",
    "            #print (filepath)\n",
    "            res= subprocess.call(filepath, shell=True)\n",
    "            #print (res)\n",
    "            info = \"freedisk Node S6\"\n",
    "            self.state_name='s6'\n",
    "            reward= 1\n",
    "            #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= True\n",
    "        \n",
    "        elif action == 7:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode and self.node >= self.minNode ):\n",
    "                self.state_name='s7'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'promoteNode.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Promote Worker node to Manager S7\"\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True\n",
    "            elif (self.node >= self.maxNode):\n",
    "                info = \"Maintain Manager nodes S0\"\n",
    "                self.state_name='s0'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True \n",
    "        elif action==8:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode):\n",
    "                self.state_name='s8'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'manager.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Add Manager node S8\"\n",
    "                self.node += 1\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True\n",
    "            elif (self.node >= self.maxNode):\n",
    "                info = \"Maintain Manager nodes S0\"\n",
    "                self.state_name='s8'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True \n",
    "            else:\n",
    "                #print(\"Maintain Cluster State S0\", self.attempt, self.node )\n",
    "                self.state_name='s0'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                done= False\n",
    "                info = \"from S8 to S0 \"\n",
    "                \n",
    "        elif action == 9:\n",
    "            self.obs = self.get_observation()\n",
    "            if not self.cluster:\n",
    "                #add new cluster one time only\n",
    "                try:         \n",
    "                    print(\"roll-back and enforce new cluster\")\n",
    "                    cur_dir = os.getcwd()\n",
    "                    filepath = os.path.join(cur_dir, 'nupicnewcluster.sh')\n",
    "                    print (filepath)\n",
    "                    res= subprocess.call(filepath, shell=True)\n",
    "                     \n",
    "                    self.state_name='s9'\n",
    "                    info = \"rollback and enforce new  cluster S9\"\n",
    "                    #time.sleep(300)\n",
    "                    myip = subprocess.check_output([\"docker-machine\", \"ip\", \"nupic\"])\n",
    "                    self.ip=myip.decode('utf-8').strip()\n",
    "                    reward= 1\n",
    "                    #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                    done= True\n",
    "                    self.cluster = True\n",
    "                    #print(reward)\n",
    "                    info = \"roll-back and enforce new cluster\"\n",
    "                except:\n",
    "                    pass\n",
    "                finally:\n",
    "                    pass\n",
    "            elif self.cluster:\n",
    "                self.state_name='s9'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                done= False\n",
    "                info = \"from S9 to S0 \"\n",
    "                if self.attempt > 400: \n",
    "                    done= True \n",
    "                    info = \"Exit S9 to S0 \"\n",
    "                    reward= 1 - np.amax(self.obs[:,3])\n",
    "\n",
    "            \n",
    "        else: \n",
    "            print (\"action not defined\")\n",
    "            self.state_name='s0'\n",
    "            self.obs = self.get_observation()\n",
    "            done= False\n",
    "            reward= -1  \n",
    "            info = \"action not defined\"\n",
    "        if done: \n",
    "            reward = 1\n",
    "        elif self.steps_beyond_done is None:\n",
    "            #Adaptation Failed \n",
    "            reward = 0.0 \n",
    "            self.steps_beyond_done = 0\n",
    "        else: \n",
    "            if self.steps_beyond_done == 1:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "                self.steps_beyond_done += 1\n",
    "                reward = 0.0\n",
    "        tend = tstart - time.time()\n",
    "        print (\"\\nState: \", self.state_name, \"action: \", action, \"reward: \", reward, \"# nodes:\", self.node, \"cluster: \", self.cluster )\n",
    "        #writer1.writerow([\"timestamp\",\"state\", \"action\", \"reward\", \"maxUtility\", \"duration\"])\n",
    "        self.obs = self.get_observation()\n",
    "        #self.writer.writerow([tstart,self.state_name, action, reward, np.amax(self.obs[:,4]), tend, info, self.node])\n",
    "        return self.obs, reward, done, {}\n",
    "    def reset(self):\n",
    "        #self.fileHandle.close()\n",
    "        self.state = self.get_observation()\n",
    "        self.steps_beyond_done = None\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False\n",
    "        cur_dir = os.getcwd()\n",
    "        filepath = os.path.join(cur_dir, 'deleteallnodes.sh')\n",
    "        print (filepath)\n",
    "        self.maxNode = 3 \n",
    "        self.minNode = 1 \n",
    "        #self.node = 1\n",
    "        #self.cluster= False\n",
    "        return self.state\n",
    "    def render(self, mode='human', close=False):\n",
    "        logger.warn(\"View is not allowed in this environment\")\n",
    "        return 0 \n",
    "    def close(self):\n",
    "        self.fileHandle.close()\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "    def get_observation(self):\n",
    "        try:\n",
    "            self.disk_axis = self.get_disk_observation() \n",
    "            self.mem_axis = self.get_mem_observation()\n",
    "            self.cpu_axis = self.get_cpu_observation()\n",
    "            self.net_axis = self.get_net_observation()\n",
    "            obs = np.vstack((self.cpu_axis,self.mem_axis, self.disk_axis, self.net_axis) )\n",
    "            return obs\n",
    "        except:\n",
    "            pass\n",
    "        finally: \n",
    "            pass \n",
    "    def get_cpu_observation(self):\n",
    "        try: \n",
    "            response = requests.get('http://'+self.ip+':8888/cpu', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                    cpu = results['cpu']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_cpu = results['utility_cpu']\n",
    "                    cpu_axis=[cpu, prediction, anomalyScore, anomalyLikelihood, utility_cpu]\n",
    "        except:\n",
    "            cpu_axis=[-1, -1, -1, -1, -1]\n",
    "            pass    \n",
    "        finally: \n",
    "            pass\n",
    "        return np.array(cpu_axis)\n",
    "    def get_mem_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/mem', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                mem = results['mem']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_mem = results['utility_mem']\n",
    "                mem_axis=[mem, prediction, anomalyScore, anomalyLikelihood, utility_mem]\n",
    "        except:\n",
    "            mem_axis=[-1, -1, -1, -1, -1]\n",
    "            pass     \n",
    "        finally: \n",
    "            #mem_axis=[0, 0, 0, 0, 0]\n",
    "            pass\n",
    "        return np.array(mem_axis)\n",
    "    def get_net_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/net', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                net = results['net']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_net = results['utility_net']\n",
    "                net_axis=[net, prediction, anomalyScore, anomalyLikelihood, utility_net]\n",
    "        except:\n",
    "            net_axis=[-1, -1, -1, -1, -1]\n",
    "            pass\n",
    "        finally:\n",
    "            pass \n",
    "        return np.array(net_axis)\n",
    "    def get_disk_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/disk', timeout=5)\n",
    "            if response is not None:\n",
    "                results = response.json()\n",
    "                if len(results) > 0:\n",
    "                    disk = results['disk']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_disk = results['utility_disk']\n",
    "            disk_axis=[disk, prediction, anomalyScore, anomalyLikelihood, utility_disk]\n",
    "        except:\n",
    "            disk_axis=[-1, -1, -1, -1, -1]\n",
    "            pass\n",
    "        finally:\n",
    "            \n",
    "            pass\n",
    "        return np.array(disk_axis)\n",
    "\n",
    "    def get_current_state(self):\n",
    "        current_state = self.state\n",
    "         \n",
    "        return current_state\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import numpy as np\n",
    "space = spaces.Discrete(10) \n",
    "space = spaces.Box(0, 10, shape=(1, 1), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gym_microagent\n",
    "import gym_microagent\n",
    "ENV_NAME = 'microagent-v20'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[123]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "#env = gym.make(ENV_NAME)\n",
    "env = MicroEnv()\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(env.action_space.shape) == 2\n",
    "nb_actions = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 4, 20)             1560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4, 16)             336       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4, 16)             272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4, 16)             272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4, 1)              17        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 1)              0         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "actorrnn = Sequential()\n",
    "actorrnn.add(GRU(units=20,\n",
    "              return_sequences=True,\n",
    "              unr\n",
    "              input_shape= env.observation_space.shape))\n",
    "actorrnn.add(Dense(16))\n",
    "actorrnn.add(Activation('relu'))\n",
    "actorrnn.add(Dense(16))\n",
    "actorrnn.add(Activation('relu'))\n",
    "actorrnn.add(Dense(16))\n",
    "actorrnn.add(Activation('relu'))\n",
    "actorrnn.add(Dense(nb_actions))\n",
    "actorrnn.add(Activation('linear'))\n",
    "print(actorrnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('linear'))\n",
    "print(actor.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 4, 5)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20)           0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 21)           0           action_input[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           704         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           1056        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           1056        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            33          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,849\n",
      "Trainable params: 2,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 3 but is rank 2 for 'sequential_1/gru_1/Tile' (op: 'Tile') with input shapes: [?,5,1], [2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 3 but is rank 2 for 'sequential_1/gru_1/Tile' (op: 'Tile') with input shapes: [?,5,1], [2].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0d18fa7a071b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps_warmup_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps_warmup_actor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   random_process=random_process, gamma=.99, target_model_update=1e-3)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras_rl-0.4.2-py3.6.egg/rl/agents/ddpg.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mcombined_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mstate_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mcombined_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_action_input_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcombined_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[0;32m--> 721\u001b[0;31m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[1;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[1;32m    723\u001b[0m                                                               computed_mask)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1647\u001b[0m                                      \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m                                      \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m                                      initial_state=initial_state)\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                     for dim in self.cell.state_size]\n\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m   8617\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8618\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 8619\u001b[0;31m         \"Tile\", input=input, multiples=multiples, name=name)\n\u001b[0m\u001b[1;32m   8620\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8621\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1790\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 3 but is rank 2 for 'sequential_1/gru_1/Tile' (op: 'Tile') with input shapes: [?,5,1], [2]."
     ]
    }
   ],
   "source": [
    "memory = SequentialMemory(limit=5000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "weights_filename = 'ddpg{}_weights.h5f'.format(ENV_NAME)\n",
    "checkpoint_weights_filename = 'ddpg_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'ddpg_{}_log.json'.format(ENV_NAME)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=25000)]\n",
    "callbacks += [FileLogger(log_filename, interval=25000)]\n",
    "callbacks += [TensorBoard(log_dir='./ddpg_logsv2/', histogram_freq=0, write_graph=False)]\n",
    "agent.fit(env, nb_steps=5000, callbacks=callbacks, visualize=False, verbose=1, nb_max_episode_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
