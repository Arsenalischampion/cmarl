{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import csv\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy, LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory \n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   MDP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import os\n",
    "from tempfile import mkdtemp\n",
    "from werkzeug import secure_filename\n",
    "import requests\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from gym import spaces, logger\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np \n",
    "import time \n",
    "import csv\n",
    "import pandas as pd \n",
    "\n",
    "class MicroEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        print('__init__')\n",
    "        tstart = time.time()\n",
    "        #filename1=\"dqn_logsv4.csv\"\n",
    "        #self.fileHandle = open(filename1,\"w\")\n",
    "        #self.writer = csv.writer(self.fileHandle)\n",
    "        self.maxNode = 2 \n",
    "        self.minNode = 1 \n",
    "        self.node = 1\n",
    "        self.ip = '192.168.99.100'\n",
    "        self.cluster= False\n",
    "        #self.ip = subprocess.check_output([\"docker-machine\", \"ip\", \"new-mgr\"])\n",
    "        self.cpu_axis  = self.get_cpu_observation()\n",
    "        self.mem_axis = self.get_mem_observation()\n",
    "        self.disk_axis = self.get_disk_observation()\n",
    "        self.net_axis  = self.get_net_observation()\n",
    "        self.action_space = spaces.Discrete(10)\n",
    "        self.action_space = spaces.Box(0, 9, shape=(1, 1), dtype=np.int16)\n",
    "        high = np.array([\n",
    "            self.get_cpu_observation(),\n",
    "            self.get_mem_observation(),\n",
    "            self.get_disk_observation(),\n",
    "            self.get_net_observation()])\n",
    "        low = np.array([\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5)])\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "        self.seed()\n",
    "        self.obs= 0\n",
    "        self.obs = self.get_observation()\n",
    "        self.viewer = None\n",
    "        self.state = self.get_observation()\n",
    "        self.state_name = 's0'\n",
    "        self.attempt = 0 \n",
    "        self.steps_beyond_done = None\n",
    "        self.done = False\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False \n",
    "        #self.writer.writerow([\"timestamp\",\"state\", \"action\", \"reward\", \"maxUtility\", \"duration\", \"info\", \"# node\"])\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    def step(self, action):\n",
    "        #assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        action = np.floor(action)\n",
    "        state = self.get_observation()\n",
    "        #past_stat = self.state\n",
    "        #print(state)\n",
    "        #Find the Utility Prefernces \n",
    "        # Select action \n",
    "        # get the reward value\n",
    "        tstart = time.time()\n",
    "        maxUtility = np.amax(self.obs[:,4])\n",
    "        utilityType = np.argmax(self.obs[:,4])\n",
    "        if utilityType== 0:\n",
    "            self.adapte_cpu=True \n",
    "        elif utilityType== 1:\n",
    "            self.adapte_mem = True\n",
    "        elif utilityType== 2:\n",
    "            self.adapte_disk = True\n",
    "        elif utilityType== 3:\n",
    "            self.adapte_net = True\n",
    "        self.attempt += 1\n",
    "        #print('self.adapte_cpu: ', self.adapte_cpu, 'self.adapte_mem:', self.adapte_mem, 'self.adapte_disk:',self.adapte_disk,'self.adapte_net:', self.adapte_net )\n",
    "        done=False\n",
    "        reward=0\n",
    "        info=''\n",
    "        print (\"Starting Action: \", action)\n",
    "        if action==0:\n",
    "            #print(\"Stay in State S0\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward=  np.amax(self.obs[:,3])\n",
    "            self.state_name='s0'\n",
    "        elif action == 1:\n",
    "            #print(\"Stay in State S1\")\n",
    "            self.obs = self.get_observation()\n",
    "            done = True\n",
    "            self.state_name='s1'\n",
    "            reward=  1\n",
    "        elif action == 2:\n",
    "            self.obs = self.get_observation()\n",
    "            try:\n",
    "                response = requests.get('http://'+self.ip+':8888/services/vscale/web/'+ str(self.attempt) + '/' + str(self.cpu_axis[0])+'/'+str(self.cpu_axis[3]))\n",
    "                results = response.json()\n",
    "                if results['result']=='Service converged':\n",
    "                    done=True \n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1 - np.amax(self.obs[:,3]) \n",
    "                    self.state_name='s2'\n",
    "                    info = \"Scale Up Move to State S2\"\n",
    "                else:\n",
    "                    done= False\n",
    "                    print(results)\n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1- np.amax(self.obs[:,3])  \n",
    "                    print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                    self.state_name='s0'\n",
    "                    info = \"S2 => No Scale Move back to State S0\"\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                \n",
    "                pass\n",
    "\n",
    "        elif action == 3: \n",
    "            #print(\"Maintain Cluster State S4 and delete dangling docker containers\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward= 1 - np.amax(self.obs[:,3])\n",
    "            #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= False\n",
    "            self.state_name='s0'\n",
    "            info = \"delete dangling docker containers S3\"\n",
    "            cur_dir = os.getcwd()\n",
    "            filepath = os.path.join(cur_dir, 'cleancontainers.sh')\n",
    "            print (filepath)\n",
    "            res= subprocess.call(filepath, shell=True)\n",
    "            #print (res)\n",
    "            reward = 1\n",
    "            self.state_name='s3'\n",
    "            done = True\n",
    "        elif action == 4:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode):\n",
    "                #print(\"Add Node s4\")\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'addNode.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Add Node S4\"\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                self.state_name='s4'\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                self.node +=1\n",
    "            elif self.node==5:\n",
    "                    done=True \n",
    "                    reward= 1 \n",
    "                    self.state_name='s4'\n",
    "            else:\n",
    "                #print(\"go back to Cluster State at S0: \", self.attempt)\n",
    "                done= False\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                self.state_name='s0'\n",
    "        elif action == 5:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode and self.node > self.minNode ):\n",
    "                #print(\"Delete Node S5\")\n",
    "                self.state_name='s5'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'deleteNode.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                \n",
    "                info = \"Delete Node S5\"\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                self.node -=1\n",
    "            else:\n",
    "                #print(\"Maintain Cluster State at S0: \", self.attempt, self.node, self.minNode, self.maxNode)\n",
    "                done= False\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward)\n",
    "                self.state_name='s0'\n",
    "                if self.node==1:\n",
    "                    done=True \n",
    "                    reward= 1\n",
    "                    self.state_name='s5'\n",
    "        elif action==6:\n",
    "            self.obs = self.get_observation()\n",
    "            #print(\"freedisk Space S6\")\n",
    "            cur_dir = os.getcwd()\n",
    "            filepath = os.path.join(cur_dir, 'freedisk.sh')\n",
    "            #print (filepath)\n",
    "            res= subprocess.call(filepath, shell=True)\n",
    "            #print (res)\n",
    "            info = \"freedisk Node S6\"\n",
    "            self.state_name='s6'\n",
    "            reward= 1\n",
    "            #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= True\n",
    "        \n",
    "        elif action == 7:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode and self.node >= self.minNode ):\n",
    "                self.state_name='s7'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'promoteNode.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Promote Worker node to Manager S7\"\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True\n",
    "            elif (self.node >= self.maxNode):\n",
    "                info = \"Maintain Manager nodes S0\"\n",
    "                self.state_name='s0'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True \n",
    "        elif action==8:\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode):\n",
    "                self.state_name='s8'\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'manager.sh')\n",
    "                #print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"Add Manager node S8\"\n",
    "                self.node += 1\n",
    "                reward= 1\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True\n",
    "            elif (self.node >= self.maxNode):\n",
    "                info = \"Maintain Manager nodes S0\"\n",
    "                self.state_name='s8'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                #print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True \n",
    "            else:\n",
    "                #print(\"Maintain Cluster State S0\", self.attempt, self.node )\n",
    "                self.state_name='s0'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                done= False\n",
    "                info = \"from S8 to S0 \"\n",
    "                \n",
    "        elif action == 9:\n",
    "            self.obs = self.get_observation()\n",
    "            if not self.cluster:\n",
    "                #add new cluster one time only\n",
    "                try:         \n",
    "                    print(\"roll-back and enforce new cluster\")\n",
    "                    cur_dir = os.getcwd()\n",
    "                    filepath = os.path.join(cur_dir, 'nupicnewcluster.sh')\n",
    "                    print (filepath)\n",
    "                    res= subprocess.call(filepath, shell=True)\n",
    "                     \n",
    "                    self.state_name='s9'\n",
    "                    info = \"rollback and enforce new  cluster S9\"\n",
    "                    #time.sleep(300)\n",
    "                    myip = subprocess.check_output([\"docker-machine\", \"ip\", \"nupic\"])\n",
    "                    self.ip=myip.decode('utf-8').strip()\n",
    "                    reward= 1\n",
    "                    #print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                    done= True\n",
    "                    self.cluster = True\n",
    "                    #print(reward)\n",
    "                    info = \"roll-back and enforce new cluster\"\n",
    "                except:\n",
    "                    pass\n",
    "                finally:\n",
    "                    pass\n",
    "            elif self.cluster:\n",
    "                self.state_name='s9'\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                done= False\n",
    "                info = \"from S9 to S0 \"\n",
    "                if self.attempt > 400: \n",
    "                    done= True \n",
    "                    info = \"Exit S9 to S0 \"\n",
    "                    reward= 1 - np.amax(self.obs[:,3])\n",
    "\n",
    "            \n",
    "        else: \n",
    "            print (\"action not defined\")\n",
    "            self.state_name='s0'\n",
    "            self.obs = self.get_observation()\n",
    "            done= False\n",
    "            reward= -1  \n",
    "            info = \"action not defined\"\n",
    "        if done: \n",
    "            reward = 1\n",
    "        elif self.steps_beyond_done is None:\n",
    "            #Adaptation Failed \n",
    "            reward = 0.0 \n",
    "            self.steps_beyond_done = 0\n",
    "        else: \n",
    "            if self.steps_beyond_done == 1:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "                self.steps_beyond_done += 1\n",
    "                reward = 0.0\n",
    "        tend = tstart - time.time()\n",
    "        print (\"\\nState: \", self.state_name, \"action: \", action, \"reward: \", reward, \"# nodes:\", self.node, \"cluster: \", self.cluster )\n",
    "        #writer1.writerow([\"timestamp\",\"state\", \"action\", \"reward\", \"maxUtility\", \"duration\"])\n",
    "        self.obs = self.get_observation()\n",
    "        #self.writer.writerow([tstart,self.state_name, action, reward, np.amax(self.obs[:,4]), tend, info, self.node])\n",
    "        return self.obs, reward, done, {}\n",
    "    def reset(self):\n",
    "        #self.fileHandle.close()\n",
    "        self.state = self.get_observation()\n",
    "        self.steps_beyond_done = None\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False\n",
    "        cur_dir = os.getcwd()\n",
    "        filepath = os.path.join(cur_dir, 'deleteallnodes.sh')\n",
    "        print (filepath)\n",
    "        self.maxNode = 3 \n",
    "        self.minNode = 1 \n",
    "        #self.node = 1\n",
    "        #self.cluster= False\n",
    "        return self.state\n",
    "    def render(self, mode='human', close=False):\n",
    "        logger.warn(\"View is not allowed in this environment\")\n",
    "        return 0 \n",
    "    def close(self):\n",
    "        self.fileHandle.close()\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "    def get_observation(self):\n",
    "        try:\n",
    "            self.disk_axis = self.get_disk_observation() \n",
    "            self.mem_axis = self.get_mem_observation()\n",
    "            self.cpu_axis = self.get_cpu_observation()\n",
    "            self.net_axis = self.get_net_observation()\n",
    "            obs = np.vstack((self.cpu_axis,self.mem_axis, self.disk_axis, self.net_axis) )\n",
    "            return obs\n",
    "        except:\n",
    "            pass\n",
    "        finally: \n",
    "            pass \n",
    "    def get_cpu_observation(self):\n",
    "        try: \n",
    "            response = requests.get('http://'+self.ip+':8888/cpu', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                    cpu = results['cpu']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_cpu = results['utility_cpu']\n",
    "                    cpu_axis=[cpu, prediction, anomalyScore, anomalyLikelihood, utility_cpu]\n",
    "        except:\n",
    "            cpu_axis=[-1, -1, -1, -1, -1]\n",
    "            pass    \n",
    "        finally: \n",
    "            pass\n",
    "        return np.array(cpu_axis)\n",
    "    def get_mem_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/mem', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                mem = results['mem']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_mem = results['utility_mem']\n",
    "                mem_axis=[mem, prediction, anomalyScore, anomalyLikelihood, utility_mem]\n",
    "        except:\n",
    "            mem_axis=[-1, -1, -1, -1, -1]\n",
    "            pass     \n",
    "        finally: \n",
    "            #mem_axis=[0, 0, 0, 0, 0]\n",
    "            pass\n",
    "        return np.array(mem_axis)\n",
    "    def get_net_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/net', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                net = results['net']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_net = results['utility_net']\n",
    "                net_axis=[net, prediction, anomalyScore, anomalyLikelihood, utility_net]\n",
    "        except:\n",
    "            net_axis=[-1, -1, -1, -1, -1]\n",
    "            pass\n",
    "        finally:\n",
    "            pass \n",
    "        return np.array(net_axis)\n",
    "    def get_disk_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://'+self.ip+':8888/disk', timeout=5)\n",
    "            if response is not None:\n",
    "                results = response.json()\n",
    "                if len(results) > 0:\n",
    "                    disk = results['disk']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_disk = results['utility_disk']\n",
    "            disk_axis=[disk, prediction, anomalyScore, anomalyLikelihood, utility_disk]\n",
    "        except:\n",
    "            disk_axis=[-1, -1, -1, -1, -1]\n",
    "            pass\n",
    "        finally:\n",
    "            \n",
    "            pass\n",
    "        return np.array(disk_axis)\n",
    "\n",
    "    def get_current_state(self):\n",
    "        current_state = self.state\n",
    "         \n",
    "        return current_state\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Deep Q-Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "#import gym_foo\n",
    "import gym_microagent\n",
    "#env = gym.make('foo-v16')\n",
    "env =  MicroEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/baz/ieee-demo/deleteallnodes.sh\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.reshape(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model2.add(Dense(nb_actions))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(16))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.add(Dense(16))\n",
    "model2.add(Activation('linear'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,050\n",
      "Trainable params: 1,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model output \"Tensor(\"activation_6/Identity:0\", shape=(?, 16), dtype=float32)\" has invalid shape. DQN expects a model that has one dimension for each action, in this case 10.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e1ddbc7d924f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m dqn = DQNAgent(model=model2, nb_actions=nb_actions, policy=policy, memory=memory,\n\u001b[1;32m      7\u001b[0m                 \u001b[0mnb_steps_warmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                train_interval=4, delta_clip=1.)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras_rl-0.4.2-py3.6.egg/rl/agents/dqn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, policy, test_policy, enable_double_dqn, enable_dueling_network, dueling_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model \"{}\" has more than one output. DQN expects a model that has a single output.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model output \"{}\" has invalid shape. DQN expects a model that has one dimension for each action, in this case {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model output \"Tensor(\"activation_6/Identity:0\", shape=(?, 16), dtype=float32)\" has invalid shape. DQN expects a model that has one dimension for each action, in this case 10."
     ]
    }
   ],
   "source": [
    "memory = SequentialMemory(limit=1000, window_length=1)\n",
    "policy = EpsGreedyQPolicy()\n",
    "#policy = BoltzmannQPolicy()\n",
    "#dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "#               target_model_update=1e-2, policy=policy)\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "                nb_steps_warmup=100, gamma=.99, target_model_update=100,\n",
    "               train_interval=4, delta_clip=1.)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ENV_NAME=\"PGNNv1\"\n",
    "weights_filename = 'pgnn_{}_weights.h5f'.format(ENV_NAME)\n",
    "checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    " \n",
    "log_filename = 'pgnn_{}_log.json'.format(ENV_NAME)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "callbacks += [FileLogger(log_filename, interval=100)]\n",
    "callbacks += [TensorBoard(log_dir='./pgnn_logsv1/', histogram_freq=0, write_graph=False)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=5000, log_interval=10000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights(weights_filename, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = dqn.test(env, nb_episodes=10,  visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
